<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <link rel="icon" href="%PUBLIC_URL%/favicon.ico" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="theme-color" content="#000000" />
  <meta name="description" content="Web site created using create-react-app" />
  <link rel="apple-touch-icon" href="%PUBLIC_URL%/logo192.png" />
  <!--
      manifest.json provides metadata used when your web app is installed on a
      user's mobile device or desktop. See https://developers.google.com/web/fundamentals/web-app-manifest/
    -->
  <link rel="manifest" href="%PUBLIC_URL%/manifest.json" />
  <!--
      Notice the use of %PUBLIC_URL% in the tags above.
      It will be replaced with the URL of the `public` folder during the build.
      Only files inside the `public` folder can be referenced from the HTML.

      Unlike "/favicon.ico" or "favicon.ico", "%PUBLIC_URL%/favicon.ico" will
      work correctly both with client-side routing and a non-root public URL.
      Learn how to configure a non-root public URL by running `npm run build`.
    -->
  <title>LLM Output Visualization</title>
  <!--
    Stylistic addition to the write up
    -->
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
      max-width: 1200px;
      margin: 0 auto;
      padding: 20px;
    }

    .content-section {
      background-color: #d7f8d9;
      border-radius: 15px;
      padding: 20px;
      margin: 20px 0;
    }

    .authors {
      font-size: smaller;
      color: #666;
      font-style: italic;
    }

    h1 {
      margin-top: 0;
    }

    .content-section h2 {
      color: #333;
      margin-top: 0;
    }

    header {
      font-family: monospace;
      font-size: 12px;
      line-height: 1.5em;
    }

    footer {
      margin-top: 40px;
      text-align: center;
    }
  </style>
</head>

<body>

  <header>
    <h1>Visualizing LLM outputs</h1>
    <p class="authors"> Emily Reif, Deniz Nazarova, Jared Hwang, Claire Yang </p>
    <p>
      When an LLM returns a response, we’re actually sampling from a probability distribution over many possible
      outputs. But we usually only see one of those samples—the response that gets returned.
    </p>
    <p>
      If we’re just using the model to get an answer or write some text, that’s fine. But if we want to understand how
      the model behaves—or build systems that depend on it—we need more than just one response. <b>We need to understand
      the whole distribution of possible outputs.</b>
    </p>
    <!-- <p>
      However, it's hard to grasp the shape of a distribution by reading dozens or hundreds of individual outputs. So
      how can we explore this space more effectively? Can graph lattice visualizations help show patterns beyond a
      single generation?
    </p> -->
  </header>

  <noscript>You need to enable JavaScript to run this app.</noscript>
  <div id="root"></div>
</body>

</html>